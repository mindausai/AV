%
%  outline latex source document for AV assignment 1.
%  use pdflatex to format this.
%
\documentclass[10pt,a4paper,oneclumn]{article}
\usepackage{amssymb,amsmath}            % if some maths is needed
\usepackage{graphicx}                   % if any images are to be included
% pick a different font if desired
\usepackage{times}

\title{Advanced Vision Assignment 2 Report}  % AILP: please use this title.
\author{Mindaugas Dabulskis, Marat Subkhankulov}                      % replace with name or exam number
\date{26th February 2013}                 % replace with actual date

\begin{document}

\maketitle  % insert title, author info
%
\section{Introduction}

This report describes the work carried out for the second assignment of the AV course.
The aim of the assignment was to track three coloured balls through a set of video frames.
The algorithm for ball detection and segmentation is discussed. 
The performance of the approach is evaluated using a gold standard.

\section{Algorithm and implementation}

In order to segment out the balls from the subject image (the current frame being considered), we removed background regions, and thresholded using values obtained from training data.

The following regions had to be removed from the image: 
\begin{enumerate}
\item Static background
\item Juggler's clothing
\item Juggler's hands
\item Juggler's face
\item Shadow caused by the juggler on the door
\end{enumerate}

To remove the above regions the following techniques were applied:

\begin{enumerate}
\item Mask 1: Average background subtraction
\item Mask 2: Clothing mask based on intensity
\item Mask 3: Hand skin mask based on saturation
\item Classification based on a training sample
\end{enumerate}

\begin{figure}
\centering
  \includegraphics[width=6cm]{figures/imnrgb.png}
  \includegraphics[width=6cm]{figures/original.png}
\caption{Training sample for each ball}
\end{figure}

\subsection{Mask 1: Average background}

A picture of the empty room had been given, however when subtraction of the background from the subject image did not eliminate the shadow of the door, which had similar values to the yellow ball even in normalized RGB. Thus we obtained a mean of all the frames and used the resulting image as the background; By converting the subject and the new background images to N-RGB, subtracting and thresholding out the low brightness regions we obtained a mask which eliminated:
\begin{enumerate}
\item Static background
\item Shadow on the door
\item Juggler's face
\end{enumerate}

\begin{figure}
\centering
  \includegraphics[width=3cm]{figures/av.png}
  \includegraphics[width=3cm]{figures/avnrgb.png}
  \includegraphics[width=3cm]{figures/avnrgbdif.png}
  \includegraphics[width=3cm]{figures/avnrgbhsvvalue.png}
  \includegraphics[width=3cm]{figures/avnrgbdifhsvmask.png}
\caption{Training sample for each ball}
\end{figure}

\subsection{Mask 2: Clothing mask}

Mask 1 did not remove the clothing of the juggler due to the smoothing effect of averaging; This posed a problem as the clothes had similar chromaticity to the green ball. We took advantage of the clothes' dark colour to easily theshold out the clothing using a manual threshold.

\begin{figure}
\centering
  \includegraphics[width=3cm]{figures/imnrgb.png}
  \includegraphics[width=3cm]{figures/clothes_mask.png}
\caption{Training sample for each ball}
\end{figure}

\subsection{Mask 3: Hands}
It seemed reasonable to use N-RGB for segmenting out the balls as the lighting effects were lare largely removed, however the hands of the juggler were not removed by the previous masks and had similar chromaticity to the red ball. We removed the hands by taking advantage of the skin's unique saturation value.

\begin{figure}
\centering
  \includegraphics[width=6cm]{figures/imsat.png}
  \includegraphics[width=6cm]{figures/imhsvsatmask.png}
\caption{Training sample for each ball}
\end{figure}

\subsection{Segmentation}

Having applied all of the masks the background was largely removed. Thresholding could now be performed. Conversion to N-RGB eliminated diffuse and specular lighting effects on the balls, but necessitated thresholding on all three channels; Since the intensity of all the pixels was largely the same after normalization, it was clear that the majority of variation lies in the hue of the spheres - using this single value simplified thresholding as only one channel could be used to successfully classify the ball pixels. 

\begin{figure}
\centering
  \includegraphics[width=6cm]{figures/bgremoved.png}
\caption{Training sample for each ball}
\end{figure}

Threshold values for hue were obtained from a training sample. The training sample obtained by sampling the pixel as the centroid of each ball given by the ground truth. The lower and upper thresholds were 2 standard deviations from the median of the sample - this was done to ignore outliers.

\begin{figure}
\centering
  \includegraphics[width=6cm]{figures/training.png}
  \includegraphics[width=6cm]{figures/class1.png}
  \includegraphics[width=6cm]{figures/class2.png}
  \includegraphics[width=6cm]{figures/class3.png}
\caption{Training sample for each ball}
\end{figure}


\section{Discussion and Conclusion}

\subsection{Formatting: tables}

An example of a table is shown as Table \ref{table1}. Somewhat 
different styles are allowed according to the type and purpose of the 
table. 

\begin{table} [t,h]
\caption{\label{table1} \textit{This is an example of a table.}}
\vspace{2mm}
\centerline{
\begin{tabular}{|c|c|}
\hline
ratio & decibels \\
\hline  \hline
1/1 & 0 \\
2/1 & $\approx 6$ \\
3.16 & 10 \\
10/1 & 20 \\ 
1/10 & -20 \\
100/1 & 40 \\
1000/1 & 60 \\
\hline
\end{tabular}}
\end{table}

To include text without formatting, use this
(scriptsize uses a significantly smaller font,
intermediate sizes are footnotesize and small):
{\scriptsize
\begin{verbatim}
I\O     1     2     3     4     5     6     7     8     9    10
  1  71.2   8.8   1.2   0.0   2.5   3.8   7.5   0.0   5.0   0.0
  2   0.0  87.5   1.2   0.0   2.5   2.5   0.0   5.0   0.0   1.2
  3   0.0   0.0  67.5   5.0   1.2  11.2   3.8   7.5   3.8   0.0
  4   0.0   0.0   1.2  62.5   3.8  22.5   0.0   6.2   2.5   1.2
  5   0.0   2.5   0.0   0.0  76.2   0.0   1.2   6.2   0.0  13.8
  6   5.0   1.2   6.2  21.2   5.0  47.5   1.2   5.0   1.2   6.2
  7  17.5   6.2   3.8   0.0   5.0   0.0  57.5   0.0  10.0   0.0
  8   0.0   0.0   2.5   1.2   8.8   0.0   0.0  73.8   2.5  11.2
  9  11.2   0.0   2.5   8.8   2.5   3.8   5.0   2.5  61.3   2.5
 10   1.2   0.0   0.0   2.5  20.0   0.0   0.0  12.5   0.0  63.7
\end{verbatim}
}

If you want to use both columns, put it in a figure*:
(figure* uses both columns, figure just 1):
it is likely to float away to an unexpecte place, though.
\begin{figure*}[h]
  \centering
{\small
\begin{verbatim}
I\O     1     2     3     4     5     6     7     8     9    10
  1  71.2   8.8   1.2   0.0   2.5   3.8   7.5   0.0   5.0   0.0
  2   0.0  87.5   1.2   0.0   2.5   2.5   0.0   5.0   0.0   1.2
  3   0.0   0.0  67.5   5.0   1.2  11.2   3.8   7.5   3.8   0.0
  4   0.0   0.0   1.2  62.5   3.8  22.5   0.0   6.2   2.5   1.2
  5   0.0   2.5   0.0   0.0  76.2   0.0   1.2   6.2   0.0  13.8
  6   5.0   1.2   6.2  21.2   5.0  47.5   1.2   5.0   1.2   6.2
  7  17.5   6.2   3.8   0.0   5.0   0.0  57.5   0.0  10.0   0.0
  8   0.0   0.0   2.5   1.2   8.8   0.0   0.0  73.8   2.5  11.2
  9  11.2   0.0   2.5   8.8   2.5   3.8   5.0   2.5  61.3   2.5
 10   1.2   0.0   0.0   2.5  20.0   0.0   0.0  12.5   0.0  63.7
\end{verbatim}
}

  \caption{Confusion Matrix}
  
\end{figure*}

\subsection{Maths, if needed}

%
%\vspace{-3mm}
\begin{equation}
x(t) = s(f_\omega(t))
\label{eq1}
\end{equation}
where \(f_\omega(t)\) is a special warping function
\begin{equation}
f_\omega(t)=\frac{1}{2\pi j}\oint_C \frac{\nu^{-1k}d\nu}
{(1-\beta\nu^{-1})(\nu^{-1}-\beta)}
\label{eq2}
\end{equation}
A residue theorem states that
\begin{equation}
\oint_C F(z)dz=2 \pi j \sum_k Res[F(z),p_k]
\label{eq3}
\end{equation}
Applying (\ref{eq3}) to (\ref{eq1}), 
it is straightforward to see that
\begin{equation}
1 + 1 = \pi
\label{eq4}
\end{equation}

And here is an included image (png and pdf formats are allowed).

\subsection{References}

References should be numbered in order of appearance, 
for example \cite{ES1}, \cite{ES2}, and \cite{ES3}. 
You \emph{can} use \texttt{bibtex} to prepare references,
or do it by hand if there are very few.

%
\bibliographystyle{IEEEtran}
\begin{thebibliography}{10}
\bibitem[1]{ES1} Smith, J. O. and Abel, J. S., 
``Bark and {ERB} Bilinear Transforms'', 
IEEE Trans. Speech and Audio Proc., 7(6):697--708, 1999.  
\bibitem[2]{ES2} Lee, K.-F., Automatic Speech Recognition: 
The Development of the 
SPHINX SYSTEM, Kluwer Academic Publishers, Boston, 1989.
\bibitem[3]{ES3} Rudnicky, A. I., Polifroni, Thayer, E. H.,
 and Brennan, R. A.  
"Interactive problem solving with speech", J. Acoust. Soc. Amer., 
Vol. 84, 1988, p S213(A).
\end{thebibliography}
\end{document}
